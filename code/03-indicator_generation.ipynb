{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a2d55d",
   "metadata": {},
   "source": [
    "# Bradford 0-19 Children and Young Peoples' Outcomes Framework: Indicator Generation for Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d74298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from rich import print\n",
    "from tabulate import tabulate\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import IFrame\n",
    "import warnings\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "from utils import (\n",
    "    make_crosstab,\n",
    "    report_value_counts\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a0b97",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "# Note: The connection string is specific to the Connected Bradford VDE.\n",
    "# Replace the placeholder below with the internal server URL.\n",
    "conn_str = \"DATABASE_URL_PLACEHOLDER\"\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "tbl_name = \"person_linked_2016plus\"\n",
    "\n",
    "df = pd.read_sql(f\"SELECT * FROM [dbo].[{tbl_name}_cleaned]\", engine)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bcd59d",
   "metadata": {},
   "source": [
    "## Set up global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "YES = 1\n",
    "NO = 0\n",
    "\n",
    "df_raw = df.copy() # keep a copy of raw linked data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7652c32",
   "metadata": {},
   "source": [
    "# Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d106f0",
   "metadata": {},
   "source": [
    "1. Two-Year Mandated Health Visitor Review\n",
    "\n",
    "| Ref | Question | Outcome(s) | Exposure(s) | Notes |\n",
    "|-----|----------|------------|-------------|-------|\n",
    "| 1.1 | Number and proportion of children aged ≥30 months who have / have not received a mandated review between ages 2–2.5 years | Receipt of 2-year review (Yes/No) | — | Descriptive |\n",
    "| 1.2 | Are socio-demographic variables associated with receipt of a review? | Receipt of 2-year review (Yes/No) | Sex; Ethnicity; IMD | Association |\n",
    "\n",
    "\n",
    "2. ASQ-3 Completion at Two-Year Review\n",
    "\n",
    "| Ref | Question | Outcome(s) | Exposure(s) | Notes |\n",
    "|-----|----------|------------|-------------|-------|\n",
    "| 2.1 | Among children with a 2-year review, number and proportion with ASQ-3 completed | ASQ-3 completion (Yes/No) | — | Descriptive |\n",
    "| 2.2 | Are socio-demographic variables associated with ASQ-3 completion? | ASQ-3 completion (Yes/No) | Sex; Ethnicity; IMD | Association |\n",
    "\n",
    "\n",
    "3. Good Level of Development (GLD) on ASQ-3\n",
    "\n",
    "| Ref | Question | Outcome(s) | Exposure(s) | Notes |\n",
    "|-----|----------|------------|-------------|-------|\n",
    "| 3.1 | Among children with ASQ-3, number and proportion in each category:<br> a) GLD achieved<br> b) Monitoring<br> c) Not GLD | Overall ASQ-3 + Domain-specific category | — | Descriptive |\n",
    "| 3.2 | Are socio-demographic variables associated with GLD (overall or by domain)? | GLD status (Yes/No); Domain status | Sex; Ethnicity; IMD | Association |\n",
    "\n",
    "\n",
    "4. Good Level of Development (GLD) on EYFSP\n",
    "\n",
    "| Ref | Question | Outcome(s) | Exposure(s) | Notes |\n",
    "|-----|----------|------------|-------------|-------|\n",
    "| 4.1 | Among children aged 5, number and proportion who reach / do not reach GLD | EYFSP GLD (Yes/No) | — | Descriptive |\n",
    "| 4.2 | Are socio-demographic variables associated with EYFSP GLD (overall or by domain)? | EYFSP GLD; Domain scores | Age (months); Sex; Ethnicity; IMD | Association |\n",
    "| 4.3 | Does non-receipt of 2-year review predict poor EYFSP GLD? Does this vary by socio-demographic factors? | EYFSP GLD (Yes/No) | 2-year review (Yes/No); Sex; Ethnicity; IMD | Prediction |\n",
    "\n",
    "5. Predictive Validity: ASQ-3 (Age 2) → EYFSP (Age 5)\n",
    "\n",
    "| Ref | Question | Outcome(s) | Exposure(s) | Notes |\n",
    "|-----|----------|------------|-------------|-------|\n",
    "| 5.1 | Is overall ASQ-3 score associated with overall EYFSP score? | EYFSP overall score | ASQ-3 overall score | Association |\n",
    "| 5.2 | Do ASQ-3 domain scores predict EYFSP domain outcomes? | EYFSP domain score | ASQ-3 domain score | Mapping below |\n",
    "| 5.3 | Does the ASQ-3–EYFSP association vary by socio-demographic variables? | EYFSP GLD / score | ASQ-3 score; Sex; Ethnicity; IMD | Interaction |\n",
    "\n",
    "**Domain Mapping**\n",
    "\n",
    "| ASQ-3 Domain | EYFSP Domain |\n",
    "|-------------|--------------|\n",
    "| Fine Motor / Gross Motor | Physical Development |\n",
    "| Communication / Language | Communication |\n",
    "| Personal & Social | Personal, Social & Emotional |\n",
    "| Problem Solving | Problem Solving |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ceaed1",
   "metadata": {},
   "source": [
    "# RQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec663cd",
   "metadata": {},
   "source": [
    "## Classify 2y home visit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419137c1",
   "metadata": {},
   "source": [
    "To estimate how many children received the mandated **2-year review (SRCode: `XaQA6`)** versus those who did not, we applied the following procedure:\n",
    "\n",
    "1. **Define age cutoffs**  \n",
    "   - We use the [Public Health England definition](https://assets.publishing.service.gov.uk/media/5bf53350e5274a2b0b42681b/Health_visitor_service_delivery_metrics_and_outcomes_definitions.pdf) of uptake of the two-year review: All children who reached 30 months (914 days) within the study period and had a two-year review coded as `XaQA6` (`Health visitor child 24-30 month contact`) completed between 691 and 914 days of age (i.e. between 23 and 30 months).\n",
    "\n",
    "2. **Classify 2y home visit review events**  \n",
    "   The two-year review (SRCode: `XaQA6`) is expected to take place when children are aged 23 to 30 months. In practice, however, some reviews are recorded outside this recommended window.\n",
    "\n",
    "   We classify each review as follows:\n",
    "   \n",
    "   - **Valid**: review date falls between 23-30 months (inclusive).  \n",
    "   - **Too early**: review recorded before 23 months.  \n",
    "   \n",
    "   A 'Too late' category is not required, as we only consider the most recent review completed before 30 months and exclude any reviews conducted after this age.\n",
    "\n",
    "1. **Group by child**  \n",
    "   - For each child (`person_id`), we checked whether they had **one valid 2y home visit entry**.  \n",
    "   - If yes → labelled as **Yes**.  \n",
    "   - If no → labelled as **No**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Each child should have only one 2y home visit record considered (the latest one before 30 months)\n",
    "\n",
    "age_23m = 691 # in days\n",
    "age_30m = 914\n",
    "\n",
    "# Calculate child's age in days at the time of HV (if available)\n",
    "df[\"age_days_at_HV\"] = (df[\"HV_DateEvent\"] - df[\"birth_datetime\"]).dt.days\n",
    "\n",
    "# Calculate child's age in days at the time of ASQ (if available)\n",
    "df[\"age_days_at_ASQ\"] = (df[\"ASQ_DateEvent\"] - df[\"birth_datetime\"]).dt.days\n",
    "\n",
    "# Prepare masks\n",
    "has_hv = df[\"HV_CTV3Code\"].eq(\"XaQA6\") & df[\"HV_DateEvent\"].notna()\n",
    "age_ok = df[\"age_days_at_HV\"].between(age_23m, age_30m)\n",
    "age_early = df[\"age_days_at_HV\"] < age_23m\n",
    "age_late = df[\"age_days_at_HV\"] > age_30m\n",
    "\n",
    "# HV_Status\n",
    "df[\"HV_Status\"] = np.select(\n",
    "    [\n",
    "        has_hv & age_ok, \n",
    "        has_hv & age_early, \n",
    "        has_hv & age_late\n",
    "    ],\n",
    "    [\n",
    "        \"Has valid 23-30m visit\", \n",
    "        \"Too early (<23m)\", \n",
    "        \"Too late (>30m)\"\n",
    "    ],\n",
    "    default=\"Eligible but no review\"\n",
    ")\n",
    "\n",
    "# Valid_2y_HV (YES / NO)\n",
    "df[\"Valid_2y_HV\"] = np.where(has_hv & age_ok, YES, NO)\n",
    "\n",
    "df_person = df[[\"person_id\", \"HV_Status\", \"Valid_2y_HV\"]].drop_duplicates()\n",
    "\n",
    "# Verification\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"HV_Status\",\n",
    "    col_var=\"Valid_2y_HV\",\n",
    "    caption_prefix=\"HV Status x Valid 2y HV\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2fe0bf",
   "metadata": {},
   "source": [
    "# RQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c8192e",
   "metadata": {},
   "source": [
    "## Classify ASQ-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb7b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['age_months_at_ASQ'] = (df[\"ASQ_DateEvent\"] - df[\"birth_datetime\"]).dt.days / 30.4375\n",
    "\n",
    "# Mask: ASQ exists and text contains 24/27/30 month\n",
    "asq_mask = (\n",
    "    df[\"ASQ_DateEvent\"].notna() &\n",
    "    df[\"ASQ_CTV3Text\"].str.contains(\n",
    "        r\"(24\\s*month|27\\s*month|30\\s*month)\",\n",
    "        flags=re.IGNORECASE, regex=True, na=False\n",
    "    )\n",
    ")\n",
    "\n",
    "# Age-based conditions\n",
    "age_ok = df[\"age_days_at_ASQ\"].between(age_23m, age_30m)\n",
    "age_early = df[\"age_days_at_ASQ\"] < age_23m\n",
    "age_late = df[\"age_days_at_ASQ\"] > age_30m\n",
    "\n",
    "# Valid 2y ASQ (YES/NO)\n",
    "df[\"Valid_2y_ASQ\"] = np.where(asq_mask & age_ok, YES, NO)\n",
    "\n",
    "# ASQ Status\n",
    "df[\"ASQ_Status\"] = np.select(\n",
    "    [\n",
    "        asq_mask & age_ok,\n",
    "        asq_mask & age_early,\n",
    "        asq_mask & age_late\n",
    "    ],\n",
    "    [\n",
    "        \"Has valid 23-30m visit\",\n",
    "        \"Too early (<23m)\",\n",
    "        \"Too late (>30m)\"\n",
    "    ],\n",
    "    default=None\n",
    ")\n",
    "\n",
    "df[\"ASQ_Version\"] = df[\"ASQ_Version\"].replace([\"Missing\", \"missing\", \"None\", \"none\", \"\"], pd.NA)\n",
    "df[\"ASQ_Version_Count\"] = df.groupby(\"person_id\")[\"ASQ_Version\"].transform(lambda x: x.dropna().nunique()) # regardless domain\n",
    "df[\"Multi_ASQ_Version\"] = df[\"ASQ_Version_Count\"] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4054ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "df_person = df[[\"person_id\", \"ASQ_Version_Count\", \"Valid_2y_ASQ\", \"ASQ_Status\", \"ASQ_Version\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"ASQ_Status\",\n",
    "    col_var=[\"ASQ_Version\", \"Valid_2y_ASQ\"],\n",
    "    caption_prefix=\"ASQ_Status x ASQ_Version x Valid_2y_ASQ\"\n",
    ")\n",
    "\n",
    "df_person[\"Valid_2y_ASQ_All\"] = (\n",
    "    df_person.groupby(\"person_id\")[\"Valid_2y_ASQ\"]\n",
    "    .transform(lambda x: \", \".join(\n",
    "        sorted(\n",
    "            x.dropna().astype(str).unique()\n",
    "        )\n",
    "    ))\n",
    ")\n",
    "df_person = df_person[[\"person_id\", \"ASQ_Version_Count\", \"Valid_2y_ASQ_All\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"ASQ_Version_Count\",\n",
    "    col_var=\"Valid_2y_ASQ_All\",\n",
    "    caption_prefix=\"ASQ_Version_Count x Valid 2y ASQ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219c718",
   "metadata": {},
   "source": [
    "# RQ3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a6d969",
   "metadata": {},
   "source": [
    "## Derive domain-level ASQ classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430e90e",
   "metadata": {},
   "source": [
    "Each domain score is categorised into one of three levels based on age-specific cut-offs:\n",
    "\n",
    "| Category          | Interpretation                                                  |\n",
    "|-------------------|-----------------------------------------------------------------|\n",
    "| **Below Cut-Off** | Requires further assessment or professional intervention        |\n",
    "| **Monitor**       | Development should be monitored                                 |\n",
    "| **Above Cut-Off** | Development is on schedule                                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2606650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asign ASQ domain based on ASQ_CTV3Text\n",
    "text = df[\"ASQ_CTV3Text\"].str.lower()\n",
    "\n",
    "df[\"ASQ_Domain\"] = np.select(\n",
    "    [\n",
    "        text.str.contains(\"communication\", na=False),\n",
    "        text.str.contains(\"gross motor\", na=False),\n",
    "        text.str.contains(\"fine motor\", na=False),\n",
    "        text.str.contains(\"problem solving\", na=False),\n",
    "        text.str.contains(\"personal-social\", na=False)\n",
    "    ],\n",
    "    [\n",
    "        \"Communication\",\n",
    "        \"Gross Motor\",\n",
    "        \"Fine Motor\",\n",
    "        \"Problem Solving\",\n",
    "        \"Personal-Social\"\n",
    "    ],\n",
    "    default=\"Unknown\"\n",
    ")\n",
    "\n",
    "df[\"ASQ_Domain\"] = df[\"ASQ_Domain\"].replace(\"Unknown\", np.nan)\n",
    "\n",
    "df[\"ASQ_Version_All\"] = (\n",
    "    df.groupby([\"person_id\", \"ASQ_Domain\"])[\"ASQ_Version\"]\n",
    "    .transform(lambda x: \", \".join(sorted(x.dropna().astype(str).unique())))\n",
    ")\n",
    "\n",
    "report_value_counts(\n",
    "    df, \n",
    "    [\"ASQ_CTV3Text\", \"ASQ_Domain\"], \n",
    "    mode='style', \n",
    "    caption=\"ASQ_CTV3Text and corresponding mapped ASQ_Domain\",\n",
    "    max_height=300, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "\n",
    "df_person = df[[\"person_id\", \"ASQ_Domain\", \"ASQ_Version_All\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"ASQ_Version_All\",\n",
    "    col_var=\"ASQ_Domain\",\n",
    "    caption_prefix=\"ASQ_Domain_All x ASQ_Domain\",\n",
    "    pct=True,\n",
    "    show_total=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529752f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asq_cutoffs_dict = {\n",
    "    \"ASQ-3 24m\": {\n",
    "        \"Communication\":      {\"below\": 25, \"monitor\": 38},\n",
    "        \"Gross Motor\":        {\"below\": 38, \"monitor\": 45},\n",
    "        \"Fine Motor\":         {\"below\": 35, \"monitor\": 43},\n",
    "        \"Problem Solving\":    {\"below\": 29, \"monitor\": 39},\n",
    "        \"Personal-Social\":    {\"below\": 31, \"monitor\": 40},\n",
    "    },\n",
    "    \"ASQ-3 27m\": {\n",
    "        \"Communication\":      {\"below\": 24, \"monitor\": 36},\n",
    "        \"Gross Motor\":        {\"below\": 28, \"monitor\": 38},\n",
    "        \"Fine Motor\":         {\"below\": 18, \"monitor\": 30},\n",
    "        \"Problem Solving\":    {\"below\": 27, \"monitor\": 39},\n",
    "        \"Personal-Social\":    {\"below\": 25, \"monitor\": 35},\n",
    "    },\n",
    "    \"ASQ-3 30m\": {\n",
    "        \"Communication\":      {\"below\": 33, \"monitor\": 44},\n",
    "        \"Gross Motor\":        {\"below\": 36, \"monitor\": 44},\n",
    "        \"Fine Motor\":         {\"below\": 19, \"monitor\": 34},\n",
    "        \"Problem Solving\":    {\"below\": 27, \"monitor\": 39},\n",
    "        \"Personal-Social\":    {\"below\": 32, \"monitor\": 40},\n",
    "    }\n",
    "}\n",
    "\n",
    "asq_cutoffs = (\n",
    "    pd.DataFrame([\n",
    "        {\"ASQ_Version\": ver, \"ASQ_Domain\": dom, **vals}\n",
    "        for ver, domains in asq_cutoffs_dict.items()\n",
    "        for dom, vals in domains.items()\n",
    "    ]).rename(\n",
    "        columns={\n",
    "            \"below\": \"ASQ_Cutoff_Below\",\n",
    "            \"monitor\": \"ASQ_Cutoff_Monitor\"\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "display(asq_cutoffs.style.hide(axis='index').set_caption(\"ASQ Cutoffs\"))\n",
    "\n",
    "df = df.merge(\n",
    "    asq_cutoffs,\n",
    "    on=['ASQ_Version', 'ASQ_Domain'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# df['ASQ_value'] = df['ASQ_value'].astype(float)\n",
    "df['ASQ_value'] = pd.to_numeric(df['ASQ_value'], errors='coerce')\n",
    "\n",
    "if (df['ASQ_Cutoff_Monitor'] < df['ASQ_Cutoff_Below']).any():\n",
    "    raise ValueError(\"Invalid cutoff: monitor < below.\")\n",
    "\n",
    "if (df[['ASQ_Cutoff_Monitor','ASQ_Cutoff_Below']] > 61).any().any():\n",
    "    raise ValueError(\"Thresholds cannot exceed 61.\")\n",
    "\n",
    "invalid_value_mask = ~(df['ASQ_value'].between(0, 61)) & df['ASQ_value'].notna()\n",
    "if invalid_value_mask.any():\n",
    "    bad_vals = df.loc[invalid_value_mask, 'ASQ_value'].unique()\n",
    "    raise ValueError(f\"Invalid ASQ_value outside 0-61: {bad_vals}\")\n",
    "\n",
    "value = df['ASQ_value']\n",
    "below = df['ASQ_Cutoff_Below']\n",
    "monitor = df['ASQ_Cutoff_Monitor']\n",
    "\n",
    "df['ASQ_Category'] = np.select(\n",
    "    [\n",
    "        value.isna(),\n",
    "        value <= below,\n",
    "        value <= monitor,\n",
    "        value <= 60,\n",
    "        value == 61\n",
    "    ],\n",
    "    [\n",
    "        None,\n",
    "        'Below Cut-Off',\n",
    "        'Monitor',\n",
    "        'Above Cut-Off',\n",
    "        'Invalid Score'\n",
    "    ],\n",
    "    default='Invalid Score'\n",
    ")\n",
    "\n",
    "assert (df['ASQ_Category'] == 'Invalid Score').sum() == 0, \"Some ASQ records have 'Invalid Score' category assigned!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c129127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "\n",
    "df_person = df[[\"person_id\", \"ASQ_Category\", \"ASQ_Domain\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"ASQ_Category\",\n",
    "    col_var=\"ASQ_Domain\",\n",
    "    caption_prefix=\"ASQ_Category x ASQ_Domain\",\n",
    "    show_total=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb81793",
   "metadata": {},
   "source": [
    "## Derive binary overall ASQ indicators and continuous ASQ composite score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9dc379",
   "metadata": {},
   "source": [
    "Two binary indicators are derived to summarise each child’s overall developmental status, following two conventions:\n",
    "\n",
    "**(1) PHE Convention (Public Health England definition)**  \n",
    "- **At Risk (0):** If *any* of the five domains are classified as **Below Cut-Off**.  \n",
    "- **Not at Risk (1):** If *all* domains are either **Monitor** or **Above Cut-Off**.\n",
    "\n",
    "**(2) FGLD Convention (Full Good Level of Development)**  \n",
    "- **Good Level of Development (1):** If *all* five domains are **Above Cut-Off** (“No Risk”).  \n",
    "- **Not GLD (0):** If *any* domain is classified as **Monitor** or **Below Cut-Off**.\n",
    "\n",
    "<br>\n",
    "A continuous composite score is also calculated:\n",
    "\n",
    "$\\text{ASQ Composite Score} = \\sum_{d=1}^{5} \\text{DomainBinary}_d$\n",
    "\n",
    "Each domain contributes:  \n",
    "- 1 = Above Cut-Off (No Risk)  \n",
    "- 0 = Monitor or Below Cut-Off  \n",
    "\n",
    "This produces a total score ranging from **0 to 5**, where higher values indicate **fewer developmental concerns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary indicator for domain\n",
    "# For FGLD: 1 = Not at risk (Above), 0 = At risk (Below or Monitor)\n",
    "df['ASQ_DomainBinary_FGLD'] = df['ASQ_Category'].map({\n",
    "    'Above Cut-Off': 1, # Not at risk\n",
    "    'Monitor': 0,\n",
    "    'Below Cut-Off': 0\n",
    "}).astype(\"Int64\")\n",
    "\n",
    "# For PHE: 1 = Not at risk (Above or Monitor), 0 = At risk (Below)\n",
    "df['ASQ_DomainBinary_PHE'] = df['ASQ_Category'].map({\n",
    "    'Above Cut-Off': 1,   # Not at risk\n",
    "    'Monitor': 1,         # Not at risk\n",
    "    'Below Cut-Off': 0,   # At risk\n",
    "}).astype(\"Int64\")\n",
    "\n",
    "\n",
    "dup_groups = df[df['Valid_2y_ASQ'] == YES].drop_duplicates(subset=['person_id', 'ASQ_CTV3Code', 'ASQ_value']) \\\n",
    "                .groupby([\"person_id\", \"ASQ_Version\"])[\"ASQ_Domain\"] \\\n",
    "                .apply(lambda x: x.size != x.nunique())\n",
    "\n",
    "violations = dup_groups[dup_groups].index\n",
    "\n",
    "assert not dup_groups.any(), f\"Duplicated ASQ_Domain found in groups: {list(violations)}\"\n",
    "\n",
    "asq_summary = (\n",
    "    df[df['Valid_2y_ASQ'] == YES]\n",
    "    .drop_duplicates(subset=['person_id', 'ASQ_CTV3Code', 'ASQ_value'])\n",
    "    .groupby(['person_id', 'ASQ_Version'])\n",
    "    .agg(\n",
    "        n_domains=('ASQ_Domain', 'nunique'),\n",
    "        n_fgld_ok=('ASQ_DomainBinary_FGLD', 'sum'), # for FGLD\n",
    "        n_phe_ok=('ASQ_DomainBinary_PHE', 'sum'),  # for PHE\n",
    "        n_asq_entries=('ASQ_Domain', 'size')\n",
    "    )\n",
    "    .assign(\n",
    "        ASQ_Composite=lambda x: np.where(x['n_domains'] == 5, x['n_fgld_ok'], np.nan),\n",
    "        \n",
    "        # PHE: 1 = Not at risk, 0 = At risk\n",
    "        ASQ_PHE_Risk=lambda x: np.where(\n",
    "            x['n_domains'] == 5,\n",
    "            np.where(x['n_phe_ok'] < 5, 0, 1),\n",
    "            np.nan\n",
    "        ),\n",
    "        \n",
    "        # FGLD: 1 = GLD, 0 = Not GLD\n",
    "        ASQ_FGLD=lambda x: np.where(\n",
    "            x['n_domains'] == 5,\n",
    "            np.where(x['n_fgld_ok'] < 5, 0, 1),\n",
    "            np.nan\n",
    "        )\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            'n_domains': 'ASQ_n_domains',\n",
    "            'n_fgld_ok': 'ASQ_n_fgld_ok',\n",
    "            'n_phe_ok': 'ASQ_n_phe_ok',\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "assert (asq_summary['n_asq_entries'] != asq_summary['ASQ_n_domains']).sum() == 0, 'Found duplicated ASQ domains'\n",
    "assert asq_summary['ASQ_n_fgld_ok'].between(0, 5).all(), \"Found ASQ_Composite values outside [0, 5] range\"\n",
    "\n",
    "\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    asq_summary,\n",
    "    on=['person_id', 'ASQ_Version'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "int_cols = ['ASQ_Composite', 'ASQ_PHE_Risk', 'ASQ_FGLD', 'ASQ_n_fgld_ok', 'ASQ_n_phe_ok', 'ASQ_n_domains']\n",
    "df[int_cols] = df[int_cols].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "\n",
    "df_person = df[[\"person_id\", \"ASQ_n_fgld_ok\", \"ASQ_n_domains\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"ASQ_n_fgld_ok\",\n",
    "    col_var=\"ASQ_n_domains\",\n",
    "    caption_prefix=\"ASQ_n_fgld_ok x ASQ_n_domains\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8726ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "\n",
    "df_person = df[[\"person_id\", \"ASQ_n_fgld_ok\", \"ASQ_FGLD\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"ASQ_n_fgld_ok\",\n",
    "    col_var=\"ASQ_FGLD\",\n",
    "    caption_prefix=\"ASQ_n_fgld_ok x ASQ_FGLD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ecbc8b",
   "metadata": {},
   "source": [
    "# RQ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2becea9",
   "metadata": {},
   "source": [
    "## Calculate binary GLD indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0cba4c",
   "metadata": {},
   "source": [
    "**Variable selection and data harmonisation**\n",
    "\n",
    "For the EYFSP dataset, multiple versions of variable naming conventions were present across extracts.  \n",
    "\n",
    "In particular, the *Personal, Social and Emotional Development (PSE)* domain included both:\n",
    "\n",
    "- assessment sub-items (e.g., `FSP_PSE_AS1`, `FSP_PSE_AS2`), and  \n",
    "- an aggregated total score (`FSP_PSE_TOTAL`),  \n",
    "\n",
    "in addition to the three formal Early Learning Goals (ELGs):  \n",
    "`FSP_PSE_G06` (*Self-confidence and Self-awareness*),  \n",
    "`FSP_PSE_G07` (*Managing Feelings and Behaviour*), and  \n",
    "`FSP_PSE_G08` (*Making Relationships*).\n",
    "\n",
    "To ensure consistency with the national EYFSP framework, **only the official ELG variables (those ending in `_G`) were retained** for analysis across all domains.  \n",
    "\n",
    "Variables corresponding to sub-assessments (`_AS`) or domain totals (`_TOTAL`) were excluded from the computation of both the total EYFSP score and the Good Level of Development (GLD) indicator.\n",
    "\n",
    "<br>\n",
    "\n",
    "The EYFSP source table includes a variable `FSP_GLD`, but this field assigns a value of 0 to some children who have *no* valid EYFSP assessment recorded (e.g., all ELGs marked as “A”, or all ELGs missing). According to DfE guidance, a child should be assessed against each of the 17 Early Learning Goals (ELGs), and the code “A” is used when a judgement cannot be made (e.g., exemption).\n",
    "\n",
    "Because a code of “A” indicates that **no judgement was made**, rather than that the child did not achieve the expected level, we do not treat these cases as “Not GLD”. Instead, when all ELG scores for a child are missing or recorded as “A”, we classify the GLD outcome as *missing* (i.e., insufficient information to determine GLD), and we derive a new GLD variable (`FSP_GLD_derived`) based solely on valid ELG assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f161539",
   "metadata": {},
   "outputs": [],
   "source": [
    "elg_domains = {\n",
    "    'PSE': 'Personal, Social and Emotional',\n",
    "    'COM': 'Communication and Language',\n",
    "    'PHY': 'Physical Development', \n",
    "    'LIT': 'Literacy',\n",
    "    'MAT': 'Mathematics (Problem Solving, Reasoning and Numeracy)',\n",
    "    'UTW': 'Understanding the World',\n",
    "    'EXP': 'Expressive Arts and Design' \n",
    "}\n",
    "\n",
    "domain_cols = {\n",
    "    k: [c for c in df.columns if c.startswith(f'FSP_{k}_G')]\n",
    "    for k in elg_domains.keys()\n",
    "}\n",
    "\n",
    "core_for_gld = ['COM', 'PHY', 'PSE', 'LIT', 'MAT']\n",
    "core_cols = [col for d in core_for_gld for col in domain_cols[d]]\n",
    "\n",
    "def highlight_core(row):\n",
    "    if row['Domain Code'] in core_for_gld:\n",
    "        return ['background-color: #ffe599'] * len(row)\n",
    "    else:\n",
    "        return [''] * len(row)\n",
    "\n",
    "domain_table = (\n",
    "    pd.DataFrame([\n",
    "        {\n",
    "            \"Domain Code\": k,\n",
    "            \"Domain Name\": elg_domains[k],\n",
    "            \"Number of ELG Columns\": len(v),\n",
    "            \"ELG Columns\": \", \".join(v)\n",
    "        }\n",
    "        for k, v in domain_cols.items()\n",
    "    ])\n",
    "    .sort_values(\"Domain Code\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(\n",
    "    domain_table\n",
    "    .style\n",
    "    .hide(axis=\"index\")\n",
    "    .apply(highlight_core, axis=1)\n",
    "    .set_caption(\"EYFSP Domains and Corresponding ELG Columns (core domains have been highlighted)\")\n",
    ")\n",
    "\n",
    "total_elgs = domain_table[\"Number of ELG Columns\"].sum()\n",
    "print(f\"Total ELG columns identified: {total_elgs}\")\n",
    "\n",
    "assert total_elgs == 17, f\"Expected 17 ELG columns but found {total_elgs} ELG columns.\"\n",
    "\n",
    "# Calculate GLD\n",
    "# GLD achieved if all ELGs in five core domains (COM, PHY, PSE, LIT, MAT) ≥ 2.\n",
    "\n",
    "df['FSP_GLD_derived'] = (\n",
    "    df[core_cols]\n",
    "    .apply(pd.to_numeric, errors='coerce')\n",
    "    .pipe(lambda x: np.where(\n",
    "        x.notna().all(axis=1),           # all core domains should have a valid score\n",
    "        x.ge(2).all(axis=1).astype(int), # expected or exceeding (score >= 2) and across all core ELGs\n",
    "        np.nan                           # all missing → NaN\n",
    "    ))\n",
    ")\n",
    "\n",
    "diff = df['FSP_GLD_derived'].compare(df['FSP_GLD'])\n",
    "df_compare = df.loc[diff.index, core_cols + ['FSP_GLD_derived', 'FSP_GLD']]\n",
    "if not df_compare.empty:\n",
    "    df_compare = df_compare.replace('A', np.nan).dropna(subset=core_cols, how='all', axis=0).drop_duplicates()\n",
    "    if not df_compare.empty:\n",
    "        display(df_compare)\n",
    "        # raise AssertionError(\n",
    "        #     f\"Mismatch between derived and source GLD after excluding missing ELGs.\\n\"\n",
    "        #     f\"{df_compare.shape[0]} mismatched rows above.\"\n",
    "        # )\n",
    "        warnings.warn(\n",
    "            f\"Mismatch between derived and source GLD after excluding missing ELGs.\\n\"\n",
    "            f\"{df_compare.shape[0]} mismatched rows above.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eyfsp = df[['person_id'] + core_cols].drop_duplicates().copy()\n",
    "df_eyfsp['FSP_Present'] = df_eyfsp[core_cols].notna().any(axis=1)\n",
    "\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_eyfsp[['person_id', 'FSP_Present']],\n",
    "    on='person_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "\n",
    "df_person = df[[\"person_id\", \"FSP_GLD_derived\", \"FSP_GLD\", \"FSP_Present\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"FSP_GLD_derived\",\n",
    "    col_var=\"FSP_GLD\",\n",
    "    caption_prefix=\"FSP_GLD_derived x FSP_GLD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = ['FSP_GLD_derived', 'FSP_GLD']\n",
    "df[int_cols] = df[int_cols].astype(\"Int64\")\n",
    "\n",
    "df_person = df[[\"person_id\", \"FSP_GLD_derived\", \"FSP_GLD\", \"FSP_Present\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"FSP_GLD_derived\",\n",
    "    col_var=\"FSP_GLD\",\n",
    "    caption_prefix=\"FSP_GLD_derived x FSP_GLD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff98085",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"FSP_Present\",\n",
    "    col_var=[\"FSP_GLD_derived\", \"FSP_GLD\"],\n",
    "    caption_prefix=\"FSP_Present x FSP_GLD_derived x FSP_GLD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd10fa4",
   "metadata": {},
   "source": [
    "## Calculate domain-level binary outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f14de7",
   "metadata": {},
   "source": [
    "We derived a binary attainment indicator for each of the five core EYFSP domains - **Communication and Language (COM), Physical Development (PHY), Personal, Social and Emotional Development (PSE), Literacy (LIT), and Mathematics (MAT).** Each domain consists of two or three Early Learning Goals (ELGs), which are scored as *Emerging (1)*, *Expected (2)*, or *Exceeding (3)*, with *A* indicating that the ELG was not assessed.\n",
    "\n",
    "Domain-level attainment was defined as follows:\n",
    "\n",
    "- **1 (Achieved expected level)**  \n",
    "  Assigned when *all* ELGs within that domain had a valid score **≥2** (Expected or Exceeding).  \n",
    "\n",
    "- **0 (Did not achieve expected level)**  \n",
    "  Assigned when *any* ELG within the domain had a score **<2** (Emerging).  \n",
    "\n",
    "- **Missing (NA)**  \n",
    "  Assigned when all ELGs in the domain were missing or recorded as **A**, meaning no valid judgement could be derived for that domain.\n",
    "\n",
    "This operationalisation aligns with the principle used for determining overall GLD, where meeting the expected level across all relevant ELGs is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in core_for_gld:\n",
    "    df[f\"FSP_{d}_Binary\"] = (\n",
    "        df[domain_cols[d]]\n",
    "        .apply(pd.to_numeric, errors='coerce')\n",
    "        .pipe(lambda x: np.where(\n",
    "            x.notna().all(axis=1),           # need valid scores for all ELGs\n",
    "            x.ge(2).all(axis=1).astype(int), # expected or exceeding (score >= 2)\n",
    "            np.nan                           # all missing → NaN\n",
    "        ))\n",
    "    )\n",
    "\n",
    "fsp_cols = [f\"FSP_{d}_Binary\" for d in core_for_gld]\n",
    "df[fsp_cols] = df[fsp_cols].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f7acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person = df[['person_id'] + fsp_cols + core_cols].drop_duplicates().apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "domain_stats = {}\n",
    "\n",
    "for d in core_for_gld:\n",
    "    cols = domain_cols[d]\n",
    "    domain_score = df_person[cols].sum(axis=1, min_count=1)\n",
    "    domain_stats[d] = domain_score.value_counts(dropna=False)\n",
    "\n",
    "domain_stats_df = pd.DataFrame(domain_stats).astype(\"Int64\")\n",
    "domain_stats_df.index = domain_stats_df.index.astype('Int64')\n",
    "\n",
    "# domain_stats_df[\"Total\"] = domain_stats_df.sum(axis=1).astype(\"Int64\")\n",
    "# total_row = domain_stats_df.sum(axis=0).astype(\"Int64\")\n",
    "# domain_stats_df.loc[\"Total\"] = total_row\n",
    "\n",
    "display(\n",
    "    domain_stats_df.style.set_caption('EYFSP domain total score distribution')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d53c46-7049-4ab0-bc52-d53511002dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_binary_stats = {d: df_person[d].value_counts(dropna=False) for d in fsp_cols}\n",
    "\n",
    "domain_binary_stats = pd.DataFrame(domain_binary_stats).astype(\"Int64\")\n",
    "\n",
    "display(\n",
    "    domain_binary_stats.style.set_caption('EYFSP Binary Score x EYFSP Core Domain')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b9d6a5",
   "metadata": {},
   "source": [
    "## Calculate continuous total EYFSP score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717db2d8",
   "metadata": {},
   "source": [
    "Any pupils with at least one `A` (Absent) in their results will not be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ecc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_elg_cols = [col for sublist in domain_cols.values() for col in sublist]\n",
    "\n",
    "assert df[['person_id'] + all_elg_cols].drop_duplicates().shape[0] == df.person_id.nunique()\n",
    "\n",
    "df['FSP_TotalScore'] = df[all_elg_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1, skipna=False)\n",
    "df['n_ELGs_completed'] = df[all_elg_cols].apply(pd.to_numeric, errors='coerce').notna().sum(axis=1)\n",
    "\n",
    "print(f\"{df.loc[df['n_ELGs_completed'] == 17, 'person_id'].nunique()} children had a complete EYFSP record (17/17 ELGs).\")\n",
    "print(f\"{df.loc[(df['n_ELGs_completed'] > 0) & (df['n_ELGs_completed'] < 17), 'person_id'].nunique()} children had partial EYFSP records (>0 and <17 ELGs).\")\n",
    "print(f\"{df.loc[df['n_ELGs_completed'] == 0, 'person_id'].nunique()} children had no EYFSP assessments (0 ELGs).\")\n",
    "\n",
    "# df.loc[df['n_ELGs_completed'] < 17, 'FSP_TotalScore'] = np.nan\n",
    "\n",
    "assert df['FSP_TotalScore'].dropna().between(17, 51).all(), \"Found out-of-range EYFSP total scores\"\n",
    "\n",
    "summary = (\n",
    "    df.drop_duplicates(subset='person_id')['FSP_GLD_derived']\n",
    "      .value_counts(dropna=False)\n",
    "      .rename_axis('FSP_GLD_Status')\n",
    "      .reset_index(name='Number_of_Children')\n",
    ")\n",
    "\n",
    "summary['FSP_GLD_Status'] = summary['FSP_GLD_Status'].astype('Int64')\n",
    "\n",
    "summary['Proportion (%)'] = (\n",
    "    summary['Number_of_Children']\n",
    "    / summary['Number_of_Children'].sum()\n",
    "    * 100\n",
    ").round(2)\n",
    "\n",
    "display(summary.style.hide(axis='index').set_caption('Summary of EYFSP Good Level of Development (GLD)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710213a",
   "metadata": {},
   "source": [
    "## Deriving age in months when children took EYFSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4542f76b",
   "metadata": {},
   "source": [
    "Because exact EYFSP assessment dates were not available in the source dataset, we needed to derive a proxy date. The Early Years Foundation Stage Profile (EYFSP) must be completed during the **final term of the academic year in which a child reaches age 5**, and submitted **no later than 30 June**. Based on this statutory requirement, we assigned an approximate assessment date of **15 June** within the relevant academic year.\n",
    "\n",
    "We then calculated each child’s **completed months of age at assessment** using this proxy date and their recorded date of birth. \n",
    "\n",
    "Age in completed months was derived as: $\\displaystyle \\text{Age (months)} = \\left\\lfloor \\frac{(\\text{ProxyDate} - \\text{DOB})_{\\text{days}}}{30.4375} \\right\\rfloor$.\n",
    "\n",
    "<br>\n",
    "\n",
    "> “The early years foundation stage profile is collected annually and **must be completed for all children in the final term of the reception year in which the child reaches age five (no later than 30 June in that term).**”  \n",
    "> — [*EYFSP Technical Specification 2025*, Department for Education](https://assets.publishing.service.gov.uk/media/677e429399c93b7286a3978c/EYFSP_2025_specification_v1.0.pdf)\n",
    "\n",
    "> “The EYFS profile must be completed for each child in the **final term of the academic year in which they reach age 5**.”  \n",
    "> — [*Early Years Foundation Stage Profile Handbook*, Department for Education](https://www.gov.uk/government/publications/early-years-foundation-stage-profile-handbook/early-years-foundation-stage-profile-handbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0068b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eyfsp_date_from_acadyr(ay):\n",
    "    if ay:\n",
    "        eyfsp_year = int(ay.split(\"/\")[1]) # EYFSP happens in the summer term of the second calendar year\n",
    "        return pd.to_datetime(f\"{eyfsp_year}-06-15\")\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "df['EYFSP_ProxyDate'] = df['FSP_ACADYR'].apply(eyfsp_date_from_acadyr)\n",
    "\n",
    "df['birth_datetime'] = pd.to_datetime(df['birth_datetime'], errors='coerce')\n",
    "df['EYFSP_ProxyDate'] = pd.to_datetime(df['EYFSP_ProxyDate'], errors='coerce')\n",
    "\n",
    "df['age_fsp_months'] = ((df['EYFSP_ProxyDate'] - df['birth_datetime']).dt.days / 30.4375).floordiv(1).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "\n",
    "df_person = df[[\"person_id\", \"FSP_GLD_derived\", \"age_fsp_months\"]].drop_duplicates()\n",
    "\n",
    "_ = make_crosstab(\n",
    "    df_person,\n",
    "    row_var=\"age_fsp_months\",\n",
    "    col_var=\"FSP_GLD_derived\",\n",
    "    caption_prefix=\"age_fsp_months x FSP_GLD_derived\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feec465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_fsp = df[['person_id', 'age_fsp_months', 'EYFSP_ProxyDate', 'FSP_ACADYR']].drop_duplicates()\n",
    "# multi_fsp[multi_fsp.duplicated(subset=\"person_id\", keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7180f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "\n",
    "if use_mock_set == True:\n",
    "    df.drop(index=1139261, inplace=True)\n",
    "    df.to_parquet(f'../Data/{tbl_name}_derived.parquet')\n",
    "else:\n",
    "    df.to_parquet(f'../{tbl_name}_derived.parquet')\n",
    "\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0d4a3-a221-4675-93e0-c66734f682eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "\n",
    "try:\n",
    "    df.to_sql(\n",
    "        name=f'{tbl_name}_derived',   \n",
    "        con=engine,                   \n",
    "        schema='dbo',                \n",
    "        if_exists='replace',          \n",
    "        index=False                 \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while writing to SQL Server.\")\n",
    "    print(str(e).split(\"\\n\")[0])\n",
    "\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
